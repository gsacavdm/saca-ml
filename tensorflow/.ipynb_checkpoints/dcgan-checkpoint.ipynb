{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Convolutional Generatative Adversarial Network\n",
    "\n",
    "*Source: https://www.tensorflow.org/alpha/tutorials/generative/dcgan*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install tensorflow-gpu==2.0.0-alpha0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow.keras.layers as layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 # Normalize the images to [-1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and shuffle the data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "      \n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # Note: None is the batch size\n",
    "    \n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)  \n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)    \n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "  \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Image data cannot be converted to float",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-e8aca7e79c6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mgenerated_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'gray'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2697\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2698\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2699\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2700\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2701\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5494\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    632\u001b[0m         if (self._A.dtype != np.uint8 and\n\u001b[1;32m    633\u001b[0m                 not np.can_cast(self._A.dtype, float, \"same_kind\")):\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image data cannot be converted to float\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         if not (self._A.ndim == 2\n",
      "\u001b[0;31mTypeError\u001b[0m: Image data cannot be converted to float"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
